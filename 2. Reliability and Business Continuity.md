# Reliability and Business Continuity
### 1. Reboot First for Safe AMIs
- A reboot is a safe restart of your EC2 instance that allows the operating system to shut down properly, saving everything from memory to disk, closing files, and stopping apps correctly. This process ensures the file system is in a clean state and avoids capturing any half-saved data or in-progress operations when creating an AMI form the EC2 instance. 
- That’s why AWS recommends rebooting before creating an AMI—so the image reflects a stable, consistent system without errors or corruption when you later launch a new instance from it.
### 2. Always Use Snapshots or Live Instances to Recreate Deleted AMIs
- When an AMI is accidentally deleted, you can rebuild it using one of two reliable sources:
    - EBS Snapshots – If the team backed up the instance volumes using Amazon EBS snapshots, you can restore those snapshots to new volumes and use them to create a new AMI.
    - Running EC2 Instances – If any EC2 instances were still running from the deleted AMI, you can create a new AMI from those instances directly.
### 3. Termination Protection Blocks Instance Termination, Not Scaling Events
- Auto Scaling will still try to scale in if needed, but if all instances are protected, no termination happens, and capacity settings may become out of sync until manual action is taken or protection is removed.
- The desired capacity of the Auto Scaling Group will be decremented, but the Auto Scaling Group will not be able to terminate any instance.
### 4. Use Sticky Sessions to Keep Users Logged In
- For web apps requiring session persistence, enable Sticky Sessions on your ALB to ensure a user consistently connects to the same backend instance, preventing unexpected logouts.
- The issue of users getting logged off frequently is likely caused by the load balancer sending each request to a different EC2 instance, which doesn’t remember the user’s session. The fix is to enable Sticky Sessions (also called session affinity) on the Application Load Balancer (ALB). This makes sure that all requests from a specific user go to the same EC2 instance, so their session stays active and they don’t have to keep logging in.

### 5. InstanceInitiatedShutdownBehavior setting for critical instances
- InstanceInitiatedShutdownBehavior decides whether a shutdown from inside the instance will stop or terminate the EC2 instance. If it's set to terminate, shutting down from the OS will delete the instance.
- The DisableApiTermination flag only protects against API calls like terminate-instances. If the OS shuts itself down and the instance is configured to terminate on shutdown, termination still happens. Always double-check the InstanceInitiatedShutdownBehavior setting for critical instances.

### 6. Shutdowns from Inside Bypass DisableApiTermination
- Even though DisableApiTermination is set (which blocks termination through the API), that does not stop a shutdown triggered from inside the OS. Since InstanceInitiatedShutdownBehavior is set (probably to terminate), when someone shuts down the instance from the operating system (like using Windows shutdown or Linux sudo shutdown), the instance will still be terminated, because that’s what the shutdown behavior instructs AWS to do.

### 7. Use Multi-AZ for RDS High Availability
- When deploying a production-grade RDS instance, enabling Multi-AZ is the most effective and built-in way to ensure your database stays available even during infrastructure failures.
- To make your Amazon RDS database highly available and failure-proof, the best and easiest solution is to enable Multi-AZ deployment. This means RDS will automatically create a standby replica in another Availability Zone, and if the main database fails, RDS automatically fails over to the standby, with no manual intervention needed. This ensures high availability and minimal downtime.

### 8. ELB Routes to Unhealthy Targets If No Healthy Ones Exist in an AZ
- If an ELB AZ's targets are unhealthy and there's no healthy fallback (or cross-zone load balancing isn’t enabled), the ELB will still forward traffic to the unhealthy AZ targets. ELB always accepts requests unless explicitly stopped.
- Always monitor instance health and enable cross-zone balancing for better fault tolerance.
- HTTP 503 Service Unavailable – Only happens if all targets across all AZs are unhealthy.
- HTTP 403 Forbidden – This is a permissions error, not related to health checks.

### 9. Use CloudWatch Alarms to Automate Instance Recovery
- Rebooting an EC2 instance (or any computer) helps reduce CPU utilization by clearing temporary issues that are causing the system to overwork.
- To automatically handle stuck EC2 instances due to high CPU usage, configure a CloudWatch Alarm to monitor utilization and reboot the instance when thresholds are exceeded—it's simple, serverless, and cost-effective.

### 10. Sticky Sessions for State-Dependent Apps
- Application Load Balancers support session stickiness, which uses a special cookie to ensure that all requests from a user during a session are sent to the same target. This is important for applications that store session state locally on the instance, allowing users to maintain continuity (e.g., staying logged in, shopping carts, form progress). By enabling stickiness, you avoid routing users to different targets that don't have their session state.

### 11. Use Tags for Smart Resource Management
- Tagging EC2 instances is the most efficient and scalable way to control automated actions like shutdowns in AWS. Tags allow your automation logic to filter and protect critical resources dynamically, making infrastructure management cleaner, safer, and more maintainable.
-  Using instance tags allows for dynamic, scalable filtering of resources without hardcoding logic. By adding a tag like DoNotShutdown=true to critical EC2 instances, the Lambda function can programmatically identify and exclude them from shutdown operations. This approach avoids manual tracking, keeps the logic clean, and adapts easily as infrastructure changes.

### 12. Security Group Targeting for Access Control
- A bastion host is like a security guard at the gate of a private area. It’s a server that lets you safely connect to other computers that are hidden inside a private network. You connect to the bastion host first, and then from there, you can access the private servers.
- In AWS, allowing SSH access to a bastion host from an entire security group means any instance associated with that group can SSH into the bastion. This is risky if the security group includes more instances than necessary or if those instances are not trusted, since it broadens access beyond what’s intended. Instead, SSH access to bastions should be tightly scoped—ideally limited to specific IP addresses or security groups dedicated to administration.

### 13. EC2 Detailed Monitoring for 1-Minute Metrics
- By default, Amazon EC2 provides basic monitoring with 5-minute granularity. To achieve 1-minute metric resolution—which is required for setting more responsive alarms—you need to enable detailed monitoring on the EC2 instance. This allows CloudWatch to collect and report metrics every minute without additional custom code or third-party tools.

### 14. Launch EC2 in a Different AZ to Bypass Capacity Issues
- The InsufficientInstanceCapacity error occurs when the specific instance type you are requesting is temporarily not available in the Availability Zone (AZ) you selected. Since AWS resources are distributed across multiple AZs, capacity can vary. The fastest and most efficient fix is to launch the instance in a different AZ within the same region, where capacity may be available.

### 15. Use Custom CloudWatch Metrics for RAM-Based Scaling
- By default, AWS CloudWatch does not collect memory (RAM) metrics for EC2 instances. To enable Auto Scaling based on RAM usage, you must install custom scripts or agents (like CloudWatch Agent) on each instance to collect RAM usage and **push it as a custom metric** to CloudWatch. You can then configure Auto Scaling policies to use this custom metric (RAMUtilization) as a scaling trigger.

### 16. Auto Scaling Using Load Balancer Metrics for User-Based Scaling
- AWS automatically provides a CloudWatch metric for connection count on the Load Balancer, which reflects how many users are actively connecting to your application. This metric can be used directly to trigger scaling actions in the Auto Scaling Group (ASG).
- To scale applications based on the number of users, leverage the built-in CloudWatch connection count metric from the AWS Load Balancer, which provides a direct and scalable way to trigger Auto Scaling actions in response to demand.

### 17. Route 53 Geolocation Routing
- The Geolocation routing policy in Amazon Route 53 lets you route traffic based on the location of the users making the DNS queries.
- Geolocation routing is the only policy that supports restricting access based on the user’s country or region. It allows you to configure DNS responses that serve specific records only to users from a designated geographic location.

### 18. EC2 Termination Protection & Instance Safety
- When an EC2 instance is in an Auto Scaling group, enabling instance protection ensures that Auto Scaling will not terminate it during scale-in events (even if the scaling policy suggests removing it). This is the right way to protect Auto Scaling group members from unintended termination.
- Spot Instances are designed to be interruptible by AWS, which means termination protection cannot be applied. AWS can terminate spot instances at any time when capacity is needed or the bid price is too low, so enabling termination protection isn't possible.

### 19. ALB Setup Basics
- A listener is like a door that lets traffic into your Application Load Balancer (ALB), and it needs a target group to know where to send that traffic. For better reliability, always place your targets (like EC2 instances) in different Availability Zones (AZs). Also, one target (like an EC2) can belong to more than one target group if needed.
- Listeners are the entry point for ALBs, and target groups ** must be** attached to them for traffic routing.

### 20. ElastiCache for Redis
- ElastiCache for Redis is an AWS-managed service that makes it easy to use Redis, a fast, in-memory database, for caching and real-time data processing. It helps apps run faster by storing frequently accessed data in memory, so you don’t have to fetch it from a slower database every time.

### 21. Redis Multi-AZ Properties
- When choosing the replica to promote to primary, ElastiCache for Redis chooses the replica with the least replication lag.
- If you want to promote a replica manually, you must first disable Multi-AZ and automatic failover.

### 22. HTTPCode_ELB_4XX_Count for Client Errors on ALB
- The HTTPCode_ELB_4XX_Count metric tracks client-side errors (like 400 or 403) that are generated by the Application Load Balancer itself. This helps you spot bad requests or unauthorized access attempts hitting your ALB, so you can troubleshoot or block them.
- These errors do not originate from the targets behind the load balancer. They are errors ALB generates(as seen in the name of the error) before forwarding the request.

### 23. DynamoDB Streams + Lambda for Real-Time Sync 
Use DynamoDB Streams to capture changes (like inserts, updates, deletes) in your table, and trigger AWS Lambda to process these changes in real time. This allows you to integrate dynamodb with other systems in realtime without building or managing complex infrastructure.
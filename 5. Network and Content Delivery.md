# Network and Content Delivery

### 1. AWS EC2 Traffic Can Stay Private with the Right Setup

- Traffic between EC2 instances in the same Region always uses AWS’s private network, and cross-Region traffic stays private only if you use Inter-Region VPC Peering. This ensures security, performance, and compliance for sensitive workloads.
- ⁠Traffic between two EC2 instances in the same AWS Region stays within the AWS network, even when it goes over public IP addresses
- Traffic between EC2 instances in different AWS Regions stays within the AWS network, if there is an Inter-Region VPC Peering connection between the VPCs where the two instances reside

### 2. Resolve EBS Attaching Issues with Unique Device Names

- If an Amazon EBS volume stays stuck in the "attaching" state, it’s often due to the device name already being in use on the EC2 instance. To fix this, detach the volume and reattach it using a different device name, which resolves the conflict and allows the volume to properly attach.
- A device name is the system path used by the EC2 instance to recognize and access an attached EBS volume. If the same name is reused, it can cause conflicts or attachment issues.

### 3. Combine Retention + Lifecycle for Compliance and Cost Control

- To securely manage S3 object retention and reduce storage costs, configure the "Retain Until Date" in Object Lock to prevent deletion for exactly 5 years(for instance), and pair it with an S3 Lifecycle Policy that automatically deletes the object once the retention period ends.
- This setup ensures compliance with data retention rules while eliminating the need for manual deletions, helping the organization stay secure and cost-efficient.

### 4. Ensure High Availability with Cross-AZ Replicas

- To achieve high availability in Amazon Aurora, always provision replicas in multiple Availability Zones. If all instances are in one AZ and that AZ fails, recovery must be manual.

### 5. Same-VPC Subnet Communication Works by Default

- Subnets in the same VPC can communicate with each other by default—no special setup like peering or Elastic IPs is required. Just ensure security groups allow the traffic.
- By default, all subnets within the same Amazon VPC can communicate with each other, whether they are public or private. This is because they all share the same route table and VPC network unless explicitly restricted by security groups or network ACLs.
- VPC peering is only needed for communication between different VPCs, not subnets within the same VPC.
- Elastic IPs are for public internet access, not for internal subnet communication.

### 6. Use S3 Versioning to Recover from Deletions

- Enable S3 versioning to ensure data can be recovered after accidental deletions or overwrites, especially in multi-team projects. It’s the simplest and most effective safeguard for shared S3 environments.

### 7. Use Egress-only Internet Gateway for IPv6 in Private Subnets

- To allow secure, outbound-only IPv6 internet access from private EC2 instances, use an Egress-only Internet Gateway. This avoids exposing the resources while still enabling necessary updates or communication.
- An Egress-only Internet Gateway (EIGW) is designed for IPv6 traffic, allowing instances in a private subnet to initiate outbound-only communication with the internet. It does not allow inbound traffic, which keeps the instances secure and hidden from public access
- If you want your instances to connect out to the internet (outbound), but not allow anything to connect into them (inbound). That’s exactly what an Egress-Only Internet Gateway is designed for in IPv6 scenarios.

### 8. CloudFront Needs Accurate Region for S3 Buckets

- If an S3 bucket changes regions, CloudFront must be updated to reflect the new bucket region—otherwise, requests fail due to region mismatch in the authorization header.

### 9. VPC Fundamentals

- AWS VPCs use private IP ranges (e.g., 10.0.0.0/16, 172.16.0.0/12, or 192.168.0.0/16) internally regardless of whether a subnet is public or private.
- Private IP ranges are specific blocks of IP addresses (defined by RFC 1918) that are reserved for use within private networks and are not routable on the public internet.
- Subnets within a VPC share the same VPC routing and can communicate with each other unless restricted by security groups or network ACLs.
- When you create a VPC, you must specify a range of IPv4 addresses for the VPC in the form of a Classless Inter-Domain Routing (CIDR) block.
- A VPC must be defined with a CIDR block like 10.0.0.0/16 that determines the IP address range available within the VPC.

### 10. VPC Endpoints Enable Private AWS API Access

- To avoid using the public internet for accessing AWS Systems Manager (SSM) APIs, the recommended and secure method is to use a VPC Endpoint—specifically an interface VPC endpoint powered by AWS PrivateLink. This allows EC2 instances in the VPC to privately communicate with SSM over the AWS network, without needing a NAT gateway, internet gateway, or public IP.
- A VPC Endpoint is a way to privately connect your Amazon VPC to AWS services—like S3, DynamoDB, or Systems Manager—without using the internet, NAT, or VPN.
- Gateway Endpoint – used for S3 and DynamoDB access from private subnets

### 11. Storage Gateway Ensures End-to-End Data Security

- AWS Storage Gateway connects on-premises environments with AWS cloud storage, enabling secure storage, backup, and disaster recovery by caching frequently accessed data locally while storing full datasets in AWS.
- AWS Storage Gateway ensures data in transit is secure by using SSL/TLS encryption for communication between the on-premises gateway and AWS. Once data reaches AWS, it is stored in Amazon S3 and is automatically encrypted at rest using S3-managed server-side encryption (SSE-S3). This satisfies typical auditor requirements for data encryption both in-transit and at-rest without any extra setup.

### 12. Read Replicas Must Stay Read-Only & Parameter-Matched

- Writing to a read replica: Read replicas are meant only for read operations. If you allow writes, especially without properly stopping replication, it can cause replication to fail or data inconsistency.
- max_allowed_packet mismatch: This parameter controls the maximum size of packets the server can handle. If the replica allows smaller packets than the source, it may fail to apply changes, causing replication errors.

### 13. Internet Gateway + Route Table = Outbound Internet Access

- ⁠To allow EC2 instances to access the internet (for things like downloading patches), you must:
  - Attach an Internet Gateway (IGW) to the VPC.
  - Ensure the EC2 instances are in a public subnet (a subnet with a route to the IGW).
  - ⁠Update the subnet’s route table to direct 0.0.0.0/0 traffic through the Internet Gateway.

### 14. VPC Peering Requires Routes on Both Sides

- When you create a peering connection, you must manually update route tables on both VPCs. Without bidirectional routing, peered instances can't talk—even if the connection exists.

### 15. Use One VPC for Internal Communication

- When you need private IP communication between subnets, keep them within the same VPC. It's simpler, faster, and doesn't require extra configuration or costs.
- If both subnets (one private, one public) are within the same VPC, AWS automatically provides private IP connectivity between them. No peering, NAT, or special routing is needed. All resources in the same VPC can communicate privately using their internal IPs, as long as security groups and route tables allow it.

### 16. Subnet Sizing for EC2

- If you need at least 28 EC2 instances in a subnet, a /26 is the smallest subnet size that provides enough usable IPs.
- In AWS, each subnet reserves 5 IP addresses (network address, broadcast, and 3 internal AWS addresses), so you always have 5 fewer usable IPs than the total in the subnet.
- A /26 subnet provides 64 IP addresses(i.e 2^(32-26))
- Subtracting 5 reserved by AWS → 59 usable IP addresses
- To fit at least n EC2 instances, choose a subnet size that provides at least n + 5 total IPs. For 28 instances, /26 is the smallest valid subnet.

### 17. S3 for Flexible Encryption Transitions

- S3 CopyObject in-place encryption is when you re-encrypt an existing object in the same bucket and key (without moving it) by copying it over itself using the CopyObject API.
- Amazon S3 allows in-place encryption of objects that were previously stored unencrypted. You can apply a default encryption policy on a bucket, and new uploads will be automatically encrypted. For existing objects, you can use CopyObject on the same object to apply encryption without needing to move or re-upload the object, and without downtime. This makes S3 uniquely flexible in transitioning data from unencrypted to encrypted state.

### 18. File Gateway for Hybrid File Access

- AWS Storage Gateway – File Gateway allows you to store files as objects in Amazon S3 while presenting a local NFS/SMB interface to your on-premises applications. It caches frequently accessed data locally, ensuring low-latency access to hot files while utilizing S3’s massive backend storage.
- This makes it the perfect replacement for on-premises NFS v3 drives when you want to offload data to S3 but retain fast local access to frequently used files.

### 19. MFA-Delete for Critical Actions

- When MFA-Delete is enabled on an S3 bucket, it adds an extra layer of security by requiring MFA authentication to:
  - Permanently delete object versions – ensures no one can erase critical data without MFA.
  - Suspend versioning – stopping versioning is a sensitive operation, as it may open the door to overwriting or deleting objects without retention history.

### 20. Tape Gateway for Cloud-Backed Virtual Tape Libraries

- AWS Storage Gateway offers Tape Gateway specifically to help organizations with existing tape backup infrastructure migrate to the cloud without changing their current processes.
- It presents itself as a virtual tape library (VTL) to your backup application over iSCSI and stores data in Amazon S3. This is ideal when you're using tape-based workflows and want to continue leveraging existing backup software, especially if you’ve invested in a long-term license (like 10 years, as stated).

### 21. Snowball Edge for Large Offline Data Transfers

- Use AWS Snowball Edge when transferring tens of terabytes to petabytes of data without depending on the internet, especially when you need local compute processing before uploading to AWS.

### 22. VPN for Software-Only Connections

- When you need to connect your on-premises network to AWS using only software (no special hardware), use Site-to-Site VPN, along with Customer Gateway (your side) and Virtual Private Gateway (AWS side).
- These options use internet-based encryption to create a secure tunnel. Avoid AWS Direct Connect, as it needs physical hardware and provides a dedicated private line.

### 23. Delete Markers in Versioned Buckets Prevent Deletion

- When S3 versioning is enabled, deleting an object does not remove it; it just adds a delete marker. The object is hidden from the bucket listing, but still exists. Therefore, even though the bucket appears empty in the UI, the delete markers and other object versions still remain. AWS will not allow you to delete a bucket until all versions and delete markers are removed

### 24. Use a NAT Gateway for IPv4 Internet Access from Private Subnets

- To allow instances in private subnets to initiate internet connections (but remain unreachable from the internet), route their IPv4 traffic to a NAT Gateway in a public subnet.

### 25. RDS Multi-AZ for High Availability and Automatic Failover

- RDS Multi-AZ (Multi-Availability Zone) deployment is designed for high availability and automated failover. When enabled, AWS automatically provisions a synchronous standby replica in another Availability Zone. If the primary database becomes unresponsive or fails a health check, AWS automatically fails over to the standby without any manual intervention, ensuring zero data loss for committed transactions and minimal downtime.

### 26. RDS Read Replica for Query Offloading

- An RDS Read Replica allows you to offload read-intensive operations (like ETL queries) from your production RDS instance, improving performance and user experience. By redirecting the ETL team to run their heavy queries against the read replica instead of the main production database, you reduce the load on the primary RDS, ensuring that website users aren't impacted.
- This is ideal for long-term scalability and performance isolation, especially as your data and usage grow.

### 27. OAI for Secure S3-CloudFront Access

- To securely serve private content from S3 through CloudFront, you use an Origin Access Identity (OAI). OAI is a special CloudFront user that you attach to your CloudFront distribution. Then, you update the S3 bucket policy to only allow access from that OAI, making the S3 content inaccessible directly by the public or any other source.
- This ensures that only CloudFront can access your S3 bucket content and helps you improve security while benefiting from faster content delivery.

### 28. Network ACLs and Security Groups for RDS Access

- Always verify Network ACL rules (both directions) and RDS Security Group inbound rules when there's a sudden loss of connectivity. They are the most common causes of connection failures.
- If users suddenly can't connect to your RDS instance (error 512 - Cannot connect to the database), it's most likely due to network path interruptions or firewall misconfigurations. Check Network ACL inbound rules, Network ACL outbound rules and DB Security Group inbound rules if it explicitly allow inbound connections (e.g., from the web server or app).

### 29. Use CNAME for External Domains

- In Route 53, a CNAME record lets you point your custom domain to another provider’s domain (like myapp.example.com → app.provider.com) without using fixed IPs. This way, if the provider changes their IPs, your domain automatically follows the updates.

### 30. IOPS-to-Size Ratio for io1 Volumes

- For io1 EBS volumes, you can provision up to 50 IOPS for every 1 GiB of storage. If you ask for more IOPS than this limit, AWS won’t allow it unless you make the volume bigger to match the ratio.
- So for a 100 GiB volume the limit is 100 × 50 = 5000 IOPS. This means 5000 IOPS is valid because it meets the limit, 3000 IOPS and 1000 IOPS are also valid as they are below the limit, but 7500 IOPS is invalid because it exceeds the maximum allowed for 100 GiB; to allow 7500 IOPS, you would need to increase the volume size to at least 150 GiB to stay within the 50:1 ratio. 👉 Key Rule: To request higher IOPS, you must increase the volume size to maintain the 50 IOPS per GiB ratio.

### 31. Network Load Balancer for Extreme Performance

- Use a Network Load Balancer (NLB) when you need ultra-low latency, the ability to handle millions of requests per second, and high-performance load balancing for TCP or UDP traffic. It is the best choice for highly demanding workloads such as video streaming, online gaming, or IoT applications where speed and scalability are critical.

### 32. Security Groups for Controlled Access Between VPCs

- Security Groups (SGs) are stateful and control traffic at the instance level, so you must add inbound rules to allow traffic from the other VPC. Network ACLs (NACLs) are stateless and allow all traffic by default unless you change them. That’s why SGs are the main focus for enabling cross-VPC traffic, especially when using VPC peering.

### 33. Public & Private Subnet Design (In Simple Terms)

- Put resources that need direct internet access (like web servers) in a public subnet, and keep internal resources (like databases or backend servers) in a private subnet. Use a NAT Gateway to let private subnet resources access the internet outbound only for updates, while keeping them hidden from incoming internet traffic. This setup improves security and reduces exposure.

### 34. EBS for Persistent Storage (In Simple Terms)

- Use EBS volumes to store important data because they stay intact even if the EC2 instance stops or restarts, unlike instance store, which is temporary and gets erased. Before taking snapshots, always flush application caches to make sure your backups are complete and consistent.
- EBS snapshots only save data written to the volume, so any data still in the OS or app cache might not be captured unless flushed first.
- It’s best to separate the OS and data onto different EBS volumes for easier management and backups, even though root volume persistence is supported.
- By default, data on non-root EBS volumes is kept safe even if you stop or terminate the EC2 instance (unless you manually set “Delete on Termination” to true).

### 35. IAM role error in VPC Flow Logs

- An IAM role error in VPC Flow Logs happens when the role linked to the flow log doesn’t have the right permissions or trust relationship for AWS to deliver logs to CloudWatch or S3. Once a flow log is created, you cannot change its IAM role, so fixing the error requires deleting and recreating the flow log with a properly configured role. This ensures the flow log has the access it needs to write data securely.

### 36. Safely Testing RDS Upgrades

- Before upgrading a production RDS instance, create a DB snapshot and restore it into a new instance. Upgrade the new instance and test thoroughly. This avoids risking production downtime and ensures compatibility with your workload.

### 37. HDD-backed EBS Vs SSD-backed EBS

- HDD-backed EBS volumes (st1 and sc1) cost less because they are designed for large, sequential data access like backups or logs, where speed isn’t critical.
- SSD-backed EBS volumes (gp2, gp3, io1) are more expensive because they provide fast random access and low latency, which is needed for things like boot volumes and databases.
- 👉 Simple rule: HDD = cheaper but slower, SSD = faster but costs more.

### 38. SSD-Backed Volumes for EC2 Boot Disks

- Boot volumes in EC2 require SSD-backed EBS volumes like gp2, gp3, or io1 for fast random access. HDD-backed volumes like st1 and sc1 are for cost-effective large sequential workloads (e.g., log processing) and are not supported for booting instances.

### 39. S3 Delete Markers in Versioning

- When S3 versioning is turned on, deleting a file doesn’t remove it — instead, S3 adds a delete marker to hide the file. You can recover the deleted file anytime by removing the delete marker, which makes the older version visible again. This helps protect against accidental deletions.
- GET requests do not retrieve delete marker objects

### 40. Replication Status in S3

- Replication status shows if an object in your S3 bucket has been successfully copied to the destination bucket in a replication setup. It tells you if replication is “COMPLETED”, “PENDING”, “FAILED”, or “REPLICA” (for already replicated objects). This helps you track and troubleshoot replication progress easily.

### 41. S3 Inventory for Object Replication Status

- S3 Inventory creates automated reports that show the replication status of objects in your buckets. It’s a simple way to track and identify failed replications across buckets, helping you monitor and fix issues at scale.

### 42. SSE-KMS for Encryption with Auditability

- Use SSE-KMS when you want AWS to handle encryption key management while providing full audit logs of key usage for compliance and security monitoring.
- For SSE-S3, AWS manages the keys, but it lacks detailed audit logs for key usage.

### 43. Direct Connect

- AWS Direct Connect is a dedicated, private network connection between your on-premises data center and AWS. It’s faster and more secure than using the public internet because it gives you a direct line into AWS.

### 44. Public Virtual Interface

- A Public VIF is a setup on Direct Connect that lets you access AWS public services (like S3, DynamoDB, etc.) over the private connection. Even though S3 is a public service, the Public VIF lets you reach it securely without going over the internet.

### 45. Public VIF for S3 over Direct Connect

- When you want to access S3 buckets from your on-premises network through AWS Direct Connect, you need to set up a Public Virtual Interface (Public VIF) because S3 is a public AWS service. This allows your on-premises systems to securely reach S3 over the private Direct Connect link.

### 46. File Gateway for NFS/SMB Integration

- AWS File Gateway lets your on-premises apps access Amazon S3 as if it’s a local file share using NFS or SMB protocols. It’s perfect for moving file-based workloads to the cloud and creating a hybrid storage setup without changing your existing applications.

### 47. Multi-AZ for High Availability, Read Replicas for Scaling Reads

- Multi-AZ keeps a standby database in another Availability Zone with synchronous replication, so if the main DB fails, it automatically switches over for high availability. Read Replicas use asynchronous replication to handle read-heavy traffic and can even be placed in other regions to improve performance for global users.
- Multi-AZ follows synchronous replication and spans at least two Availability Zones within a single region. Read replicas follow asynchronous replication and can be within an Availability Zone, Cross-AZ, or Cross-Region.

### 48. CloudWatch Metrics for S3 5xx Monitoring

- S3 occasionally returns 5xx server errors (like 500 Internal Server Error) due to transient issues. AWS recommends retrying the request with exponential backoff as most of these errors are temporary. CloudWatch can monitor 5xxError metrics.
- Turn on CloudWatch metrics to track 5xx errors in S3, which indicate server-side problems. Set up alerts to notify your team quickly, and use retry logic with exponential backoff in your apps to handle these errors gracefully and improve reliability.

### 49. S3 RTC for Replication SLA and Alerts

- S3 Replication Time Control (RTC) ensures your data is replicated to the destination bucket within 15 minutes, meeting a strict SLA. It also lets you set up automatic alerts if replication fails, making it an easy, AWS-managed way to monitor and guarantee replication performance.

### 50. File Gateway for Hybrid File Storage

- To migrate on-premises files to AWS and maintain access from both local systems and the cloud, use File Gateway. It supports NFS/SMB access and stores data as S3 objects with low management overhead.

### 51. AWS Handles SSE While You Manage Configurations

- Under the AWS Shared Responsibility Model, AWS is responsible for the security of the cloud, which includes the underlying infrastructure like hardware, software, networking, and facilities. This means S3 server-side encryption (SSE) is handled by AWS.
- As a customer, you are responsible for the security in the cloud, such as configuring S3 bucket policies, enabling versioning, and managing ACLs (Access Control Lists).
- In S3, AWS automatically manages server-side encryption (SSE) at the infrastructure level, but you must configure bucket policies, ACLs, and versioning for securing and managing your data.

### 52. NACLs Require Explicit Inbound and Outbound Rules

- Security Groups are stateful, so only one direction needs to be configured. But Network ACLs are stateless, requiring both inbound and outbound rules for traffic to flow properly.

### 53. ACM Certificates Are Region-Specific

- AWS Certificate Manager (ACM) certificates are region-specific. If you request or import a certificate in one region (e.g., us-east-1), it will not appear in ACM for another region (e.g., eu-west-1).
- If you want to use an ACM certificate with an ALB, ensure the certificate is requested or imported in the same AWS Region as the ALB. Certificates in other regions won’t be visible or usable.
- If you a certificate for your ALB to use, the ACM certificate must be created or imported in the same region where the ALB exists.

### 54. Pre-Warm EBS Volumes for Consistent Performance

- When you create a new EBS volume from a snapshot, the first read operation on each block can experience increased latency.
- This happens because the data is lazily loaded from Amazon S3. To avoid this, you can initialize (or pre-warm) the volume by reading all the blocks in advance, which triggers the loading process and ensures consistent performance when the volume is later used in production.
- If you want to ensure low-latency access for an EBS volume created from a snapshot, pre-warm the volume by reading all its blocks before production use. This avoids the performance impact of lazy loading.

### 55. FSx Windows File Server for Windows Storage Needs

- Amazon FSx for Windows File Server is designed specifically for Windows-based workloads. It supports Windows NTFS, SMB protocol, and integrates seamlessly with Active Directory for authentication, making it the best fit for Windows applications running on AWS.
- Amazon EFS supports NFS (Linux systems) but not NTFS/SMB.
- Amazon FSx for Lustre is optimized for high-performance computing, not Windows integration.

### 56. ELB Access Logs for HTTP(S) Traffic Analysis

- Elastic Load Balancing (ELB) Access Logs capture detailed information about requests sent to the load balancer, such as client IP addresses, request paths, latencies, and server responses. These logs help in analyzing traffic patterns and troubleshooting issues with backend EC2 instances.
- If you want to analyze HTTP/S traffic passing through an ELB—including client IPs, latencies, and request paths—enable Elastic Load Balancing Access Logs for detailed insights.

### 57. Custom Domain for CloudFront with SSL/TLS

- To use your own domain name with a CloudFront distribution instead of the default CloudFront URL, you must first register the domain name (using Route 53 or any registrar). Then, you need a valid SSL/TLS certificate (issued by ACM or a trusted CA) for HTTPS support.
- To use a custom domain with CloudFront, you must register the domain name and obtain a valid SSL/TLS certificate from ACM or another CA to enable secure HTTPS access.

### 58. Amazon EFS on Linux EC2 Instances

- Amazon EFS (Elastic File System) lets you create a shared file system that can be mounted on multiple Linux EC2 instances at the same time. It works like a network drive, so all connected instances can read and write to the same files, making it ideal for workloads like web servers, content management systems, or shared storage.
- You can mount EFS on Linux using the EFS mount helper.

### 59. EFS Mount Helper for IAM and Auto-Mount

- The EFS mount helper simplifies mounting Amazon Elastic File System (EFS) on Linux instances. It supports IAM authorization, enabling secure access to the file system without hardcoding credentials. It also allows automatic remounting on EC2 instance reboots if configured in /etc/fsta
- EFS mount helper has the following options: Mounting with IAM authorization, and Auto-mounting when an EC2 instance reboots.

### 60. NLB AZ Configuration is Immutable

- Once a Network Load Balancer (NLB) is created and associated with specific subnets in Availability Zones (AZs), you cannot remove or disable an AZ from the configuration. To exclude an AZ, you would need to create a new NLB with only the required AZs. This behavior is different from Application Load Balancers, where enabling/disabling AZs is possible after creation.

### 61. Route 53 Alias Records for AWS Integrations

- When using Route 53 to route traffic to resources like CloudFront distributions, S3 static websites, or Elastic Load Balancers, you use Alias records instead of CNAMEs. Alias records let you map a domain (e.g., https://johntrucks.com) directly to AWS resources.
- Use Route 53 Alias records when pointing domains to AWS services like CloudFront or S3 because they support root domains and integrate directly with AWS resources without needing an IP address.

### 62. EC2 Public IP Behavior in VPCs

- Public IPs are automatically assigned to instances at launch (if enabled), but you cannot manually detach or reattach them. Elastic IPs (EIPs) are required if you need static, reassignable public IPs.
- By default, Amazon EC2 and Amazon VPC use the IPv4 addressing protocol; you can't disable this behavior
- If the public IP address of your instance in a VPC has been released, it will not receive a new one if there is more than one network interface attached to your instance. i.e for IPv6 or instances with multiple ENIs, you need to manage IPs manually because AWS won’t auto-assign new public IPs in these cases.

### 63. What is AWS Storage Gateway

- AWS Storage Gateway is a hybrid cloud service that connects your on-premises storage systems to AWS. It lets you store data in AWS (like S3 or Glacier) while still allowing your local applications to access it as if it’s on a local disk or file share.

### 64. What are Cache Disks?

- A cache disk is part of the Storage Gateway setup that temporarily holds frequently accessed data locally on-premises. This makes access faster because it doesn’t always need to pull data from AWS. It’s like a local “speed booster” for the cloud storage.

### 65. Resize Cache Disks in AWS Storage Gateway by Recreating Gateway

- You cannot resize cache disks on an existing AWS Storage Gateway. If you need a smaller or larger cache disk for cost optimization, you must create a new gateway with the desired size and migrate your workloads to it. AWS does not support modifying cache disk sizes directly.

### 66. EBS Compliance

- In AWS Config, a resource is marked compliant if it follows the rules or policies you set (like encryption enabled or tags applied). For example, An EBS volume is compliant if it has encryption turned on, but if it doesn’t, AWS Config will mark it as noncompliant.
- After deletion, resources may still appear compliant for a short time until AWS Config updates.

### 67. AWS Config Delayed Deletion Visibility for EBS Volumes

- When an EC2 instance is terminated, its EBS volumes (with DeleteOnTermination=true) are also deleted, but AWS Config may still show them as compliant for a while. This happens because AWS Config checks resources on a schedule and can take up to 6 hours to update. To see the correct status sooner, you can manually refresh AWS Config.

### 68. Restore from Snapshots for Failed EBS Volumes

- Your EBS volume is like a hard drive attached to EC2, but when you create a snapshot, AWS saves a backup copy of the data in S3 (separate from the EBS hardware). So even if the original EBS hardware fails, your data is safe in the snapshot, and you can use it to create a new volume on healthy hardware.
- If an EBS volume fails and shows a status of error, it means there’s a hardware issue on AWS’s side and you can’t recover the original volume. The solution is to use your EBS snapshots (backups) to create a new volume and attach it to your EC2 instance. This works because EBS snapshots are stored separately in S3 for durability.

### 69. AWS Storage Gateway has three types
- File Gateway lets you store files in S3 and access them locally using NFS or SMB file shares, ideal for backups and cloud integration. 
- Volume Gateway provides iSCSI block storage with two modes: Stored Volumes (data saved locally and backed up to S3) and Cached Volumes (most data in S3 with a local cache for fast access). 
- Tape Gateway emulates a physical tape library, allowing you to use S3 and Glacier as virtual tapes for backup software, making it perfect for replacing traditional tape backups.

### 70. Stored Volume Snapshots for Recovery
- In AWS Storage Gateway (Stored Volumes), your data is:
  - Saved locally on your on-premises storage.
  - Backed up to AWS S3 as EBS snapshots (copies of your data in the cloud).
- If the Storage Gateway fails, you can restore your data from the EBS snapshots in AWS to a new gateway or EC2 volume.
- If the failure is because the local file system got corrupted, you can try to fix it with a tool like fsck, which repairs damaged file systems.
- Think of snapshots as a “cloud backup” you can use if your on-site gateway hardware or software has issues.

### 71. Ephemeral port
- When your computer (the client) connects to a server (like an EC2 in AWS) on port 80 or 443, the request goes from your computer’s ephemeral port (e.g., 10245) to the server’s port 80.
- The server then replies back to your computer’s ephemeral port to send the response.
- On the AWS side, if you’re using a Network ACL, you must allow outbound traffic to your computer’s ephemeral port range (**1024–65535**) so the response can get back to you.
- Key Point: The ephemeral port is on your computer (client side), but AWS must allow traffic to those ports for the connection to work.

### 72. Network ACL Outbound Ephemeral Ports 
- Network ACLs are stateless, so you must allow both inbound and outbound traffic. For internet-facing apps, even if port 80 (HTTP) is open for inbound traffic, clients expect responses on ephemeral ports (**1024–65535**). If you don’t allow outbound traffic on these ports, return traffic gets blocked, and users won’t see your website. In contrast, Security Groups are stateful and handle return traffic automatically without extra rules.

### 73. CloudFront Passes 404 Errors from Origin (In Simple Terms)

- When CloudFront can’t find an object in its cache, it forwards the request to the origin server (like S3 or EC2). If the object is missing at the origin, the origin sends back a 404 error, and CloudFront passes this error directly to the user. To handle this gracefully, you can add custom error responses in CloudFront (like redirecting to a “friendly” error page).

### 74. 404 Error (In Simple Terms):

- A 404 error means the server can’t find the file or webpage you’re asking for. It happens when the URL points to something that doesn’t exist on the server (like a deleted or missing object).
- Example: You type example.com/file.jpg, but the file file.jpg isn’t on the server—so the server replies with a 404 Not Found error.
- Key Point: A 404 means the client made a valid request, but the resource isn’t there.

### 75. S3 Bucket Naming for Static Websites

- When hosting a static website on S3 with a custom domain (like example.com), the S3 bucket name must exactly match the domain name. For example, if your domain is example.com, the bucket must be named example.com. If they don’t match, Route 53 won’t be able to resolve DNS requests to the S3 website endpoint, and the site won’t load.

### 76. ElastiCache for Memcached for Simple, Scalable Caching
- ElastiCache for Memcached is a simple, high-performance, in-memory caching solution. It’s designed to easily scale out or scale in by adding or removing nodes as demand changes. It supports horizontal scaling, which makes it ideal for workloads where you need flexibility in the number of cache nodes.
- ElastiCache for Redis is better for complex data structures and persistence, but for simple use case (simple scaling of nodes), Memcached is lighter and more appropriate.
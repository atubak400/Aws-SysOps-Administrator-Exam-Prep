# Network and Content Delivery
### 1. AWS EC2 Traffic Can Stay Private with the Right Setup
- Traffic between EC2 instances in the same Region always uses AWS’s private network, and cross-Region traffic stays private only if you use Inter-Region VPC Peering. This ensures security, performance, and compliance for sensitive workloads.
- ⁠Traffic between two EC2 instances in the same AWS Region stays within the AWS network, even when it goes over public IP addresses
- Traffic between EC2 instances in different AWS Regions stays within the AWS network, if there is an Inter-Region VPC Peering connection between the VPCs where the two instances reside
### 2. Resolve EBS Attaching Issues with Unique Device Names
- If an Amazon EBS volume stays stuck in the "attaching" state, it’s often due to the device name already being in use on the EC2 instance. To fix this, detach the volume and reattach it using a different device name, which resolves the conflict and allows the volume to properly attach.
- A device name is the system path used by the EC2 instance to recognize and access an attached EBS volume. If the same name is reused, it can cause conflicts or attachment issues.
### 3. Combine Retention + Lifecycle for Compliance and Cost Control
- To securely manage S3 object retention and reduce storage costs, configure the "Retain Until Date" in Object Lock to prevent deletion for exactly 5 years(for instance), and pair it with an S3 Lifecycle Policy that automatically deletes the object once the retention period ends. 
- This setup ensures compliance with data retention rules while eliminating the need for manual deletions, helping the organization stay secure and cost-efficient.
### 4. Ensure High Availability with Cross-AZ Replicas
- To achieve high availability in Amazon Aurora, always provision replicas in multiple Availability Zones. If all instances are in one AZ and that AZ fails, recovery must be manual.
### 5. Same-VPC Subnet Communication Works by Default
- Subnets in the same VPC can communicate with each other by default—no special setup like peering or Elastic IPs is required. Just ensure security groups allow the traffic.
- By default, all subnets within the same Amazon VPC can communicate with each other, whether they are public or private. This is because they all share the same route table and VPC network unless explicitly restricted by security groups or network ACLs.
- VPC peering is only needed for communication between different VPCs, not subnets within the same VPC.
- Elastic IPs are for public internet access, not for internal subnet communication.
### 6. Use S3 Versioning to Recover from Deletions
- Enable S3 versioning to ensure data can be recovered after accidental deletions or overwrites, especially in multi-team projects. It’s the simplest and most effective safeguard for shared S3 environments.
### 7. Use Egress-only Internet Gateway for IPv6 in Private Subnets
- To allow secure, outbound-only IPv6 internet access from private EC2 instances, use an Egress-only Internet Gateway. This avoids exposing the resources while still enabling necessary updates or communication.
- An Egress-only Internet Gateway (EIGW) is designed for IPv6 traffic, allowing instances in a private subnet to initiate outbound-only communication with the internet. It does not allow inbound traffic, which keeps the instances secure and hidden from public access
- If you want your instances to connect out to the internet (outbound), but not allow anything to connect into them (inbound). That’s exactly what an Egress-Only Internet Gateway is designed for in IPv6 scenarios.
### 8. CloudFront Needs Accurate Region for S3 Buckets
- If an S3 bucket changes regions, CloudFront must be updated to reflect the new bucket region—otherwise, requests fail due to region mismatch in the authorization header.
### 9. VPC Fundamentals 
- AWS VPCs use private IP ranges (e.g., 10.0.0.0/16, 172.16.0.0/12, or 192.168.0.0/16) internally regardless of whether a subnet is public or private.
- Private IP ranges are specific blocks of IP addresses (defined by RFC 1918) that are reserved for use within private networks and are not routable on the public internet.
- Subnets within a VPC share the same VPC routing and can communicate with each other unless restricted by security groups or network ACLs.
- When you create a VPC, you must specify a range of IPv4 addresses for the VPC in the form of a Classless Inter-Domain Routing (CIDR) block.
- A VPC must be defined with a CIDR block like 10.0.0.0/16 that determines the IP address range available within the VPC.
### 10. VPC Endpoints Enable Private AWS API Access
- To avoid using the public internet for accessing AWS Systems Manager (SSM) APIs, the recommended and secure method is to use a VPC Endpoint—specifically an interface VPC endpoint powered by AWS PrivateLink. This allows EC2 instances in the VPC to privately communicate with SSM over the AWS network, without needing a NAT gateway, internet gateway, or public IP.
- A VPC Endpoint is a way to privately connect your Amazon VPC to AWS services—like S3, DynamoDB, or Systems Manager—without using the internet, NAT, or VPN.
- Gateway Endpoint – used for S3 and DynamoDB access from private subnets
### 11. Storage Gateway Ensures End-to-End Data Security
- AWS Storage Gateway connects on-premises environments with AWS cloud storage, enabling secure storage, backup, and disaster recovery by caching frequently accessed data locally while storing full datasets in AWS.
- AWS Storage Gateway ensures data in transit is secure by using SSL/TLS encryption for communication between the on-premises gateway and AWS. Once data reaches AWS, it is stored in Amazon S3 and is automatically encrypted at rest using S3-managed server-side encryption (SSE-S3). This satisfies typical auditor requirements for data encryption both in-transit and at-rest without any extra setup.
### 12. Read Replicas Must Stay Read-Only & Parameter-Matched
- Writing to a read replica: Read replicas are meant only for read operations. If you allow writes, especially without properly stopping replication, it can cause replication to fail or data inconsistency.
- max_allowed_packet mismatch: This parameter controls the maximum size of packets the server can handle. If the replica allows smaller packets than the source, it may fail to apply changes, causing replication errors.
### 13. Internet Gateway + Route Table = Outbound Internet Access
- ⁠To allow EC2 instances to access the internet (for things like downloading patches), you must:
    - Attach an Internet Gateway (IGW) to the VPC.
    - Ensure the EC2 instances are in a public subnet (a subnet with a route to the IGW).
    - ⁠Update the subnet’s route table to direct 0.0.0.0/0 traffic through the Internet Gateway.
### 14. VPC Peering Requires Routes on Both Sides
- When you create a peering connection, you must manually update route tables on both VPCs. Without bidirectional routing, peered instances can't talk—even if the connection exists.
### 15. Use One VPC for Internal Communication
- When you need private IP communication between subnets, keep them within the same VPC. It's simpler, faster, and doesn't require extra configuration or costs.
- If both subnets (one private, one public) are within the same VPC, AWS automatically provides private IP connectivity between them. No peering, NAT, or special routing is needed. All resources in the same VPC can communicate privately using their internal IPs, as long as security groups and route tables allow it.
### 16. Subnet Sizing for EC2
- If you need at least 28 EC2 instances in a subnet, a /26 is the smallest subnet size that provides enough usable IPs.
- In AWS, each subnet reserves 5 IP addresses (network address, broadcast, and 3 internal AWS addresses), so you always have 5 fewer usable IPs than the total in the subnet.
- A /26 subnet provides 64 IP addresses(i.e 2^(32-26))
- Subtracting 5 reserved by AWS → 59 usable IP addresses
- To fit at least n EC2 instances, choose a subnet size that provides at least n + 5 total IPs. For 28 instances, /26 is the smallest valid subnet.
### 17. S3 for Flexible Encryption Transitions
- S3 CopyObject in-place encryption is when you re-encrypt an existing object in the same bucket and key (without moving it) by copying it over itself using the CopyObject API.
- Amazon S3 allows in-place encryption of objects that were previously stored unencrypted. You can apply a default encryption policy on a bucket, and new uploads will be automatically encrypted. For existing objects, you can use CopyObject on the same object to apply encryption without needing to move or re-upload the object, and without downtime. This makes S3 uniquely flexible in transitioning data from unencrypted to encrypted state.
### 18. File Gateway for Hybrid File Access
- AWS Storage Gateway – File Gateway allows you to store files as objects in Amazon S3 while presenting a local NFS/SMB interface to your on-premises applications. It caches frequently accessed data locally, ensuring low-latency access to hot files while utilizing S3’s massive backend storage.
- This makes it the perfect replacement for on-premises NFS v3 drives when you want to offload data to S3 but retain fast local access to frequently used files.
### 19. MFA-Delete for Critical Actions
- When MFA-Delete is enabled on an S3 bucket, it adds an extra layer of security by requiring MFA authentication to:
    - Permanently delete object versions – ensures no one can erase critical data without MFA.
    - Suspend versioning – stopping versioning is a sensitive operation, as it may open the door to overwriting or deleting objects without retention history.
### 20. Tape Gateway for Cloud-Backed Virtual Tape Libraries
- AWS Storage Gateway offers Tape Gateway specifically to help organizations with existing tape backup infrastructure migrate to the cloud without changing their current processes. 
- It presents itself as a virtual tape library (VTL) to your backup application over iSCSI and stores data in Amazon S3. This is ideal when you're using tape-based workflows and want to continue leveraging existing backup software, especially if you’ve invested in a long-term license (like 10 years, as stated).
### 21. Snowball Edge for Large Offline Data Transfers
- Use AWS Snowball Edge when transferring tens of terabytes to petabytes of data without depending on the internet, especially when you need local compute processing before uploading to AWS.
### 22. VPN for Software-Only Connections
- When you need to connect your on-premises network to AWS using only software (no special hardware), use Site-to-Site VPN, along with Customer Gateway (your side) and Virtual Private Gateway (AWS side). 
- These options use internet-based encryption to create a secure tunnel. Avoid AWS Direct Connect, as it needs physical hardware and provides a dedicated private line.
### 23. Delete Markers in Versioned Buckets Prevent Deletion
- When S3 versioning is enabled, deleting an object does not remove it; it just adds a delete marker. The object is hidden from the bucket listing, but still exists. Therefore, even though the bucket appears empty in the UI, the delete markers and other object versions still remain. AWS will not allow you to delete a bucket until all versions and delete markers are removed
### 24. Use a NAT Gateway for IPv4 Internet Access from Private Subnets
- To allow instances in private subnets to initiate internet connections (but remain unreachable from the internet), route their IPv4 traffic to a NAT Gateway in a public subnet.
### 25. RDS Multi-AZ for High Availability and Automatic Failover
- RDS Multi-AZ (Multi-Availability Zone) deployment is designed for high availability and automated failover. When enabled, AWS automatically provisions a synchronous standby replica in another Availability Zone. If the primary database becomes unresponsive or fails a health check, AWS automatically fails over to the standby without any manual intervention, ensuring zero data loss for committed transactions and minimal downtime.
### 26. RDS Read Replica for Query Offloading
- An RDS Read Replica allows you to offload read-intensive operations (like ETL queries) from your production RDS instance, improving performance and user experience. By redirecting the ETL team to run their heavy queries against the read replica instead of the main production database, you reduce the load on the primary RDS, ensuring that website users aren't impacted.
- This is ideal for long-term scalability and performance isolation, especially as your data and usage grow.
### 27. OAI for Secure S3-CloudFront Access
- To securely serve private content from S3 through CloudFront, you use an Origin Access Identity (OAI). OAI is a special CloudFront user that you attach to your CloudFront distribution. Then, you update the S3 bucket policy to only allow access from that OAI, making the S3 content inaccessible directly by the public or any other source.
- This ensures that only CloudFront can access your S3 bucket content and helps you improve security while benefiting from faster content delivery.
### 28. Network ACLs and Security Groups for RDS Access
- Always verify Network ACL rules (both directions) and RDS Security Group inbound rules when there's a sudden loss of connectivity. They are the most common causes of connection failures.
- If users suddenly can't connect to your RDS instance (error 512 - Cannot connect to the database), it's most likely due to network path interruptions or firewall misconfigurations. Check Network ACL inbound rules, Network ACL outbound rules and DB Security Group inbound rules if it explicitly allow inbound connections (e.g., from the web server or app).
### 29. Use CNAME for External Domains
- In Route 53, a CNAME record lets you point your custom domain to another provider’s domain (like myapp.example.com → app.provider.com) without using fixed IPs. This way, if the provider changes their IPs, your domain automatically follows the updates.
### 30. IOPS-to-Size Ratio for io1 Volumes
- For io1 EBS volumes, you can provision up to 50 IOPS for every 1 GiB of storage. If you ask for more IOPS than this limit, AWS won’t allow it unless you make the volume bigger to match the ratio.
- So for a 100 GiB volume the limit is 100 × 50 = 5000 IOPS. This means 5000 IOPS is valid because it meets the limit, 3000 IOPS and 1000 IOPS are also valid as they are below the limit, but 7500 IOPS is invalid because it exceeds the maximum allowed for 100 GiB; to allow 7500 IOPS, you would need to increase the volume size to at least 150 GiB to stay within the 50:1 ratio. 👉 Key Rule: To request higher IOPS, you must increase the volume size to maintain the 50 IOPS per GiB ratio.
### 31. Network Load Balancer for Extreme Performance
- Use a Network Load Balancer (NLB) when you need ultra-low latency, the ability to handle millions of requests per second, and high-performance load balancing for TCP or UDP traffic. It is the best choice for highly demanding workloads such as video streaming, online gaming, or IoT applications where speed and scalability are critical.
### 32. Security Groups for Controlled Access Between VPCs
- Security Groups (SGs) are stateful and control traffic at the instance level, so you must add inbound rules to allow traffic from the other VPC. Network ACLs (NACLs) are stateless and allow all traffic by default unless you change them. That’s why SGs are the main focus for enabling cross-VPC traffic, especially when using VPC peering.
### 33. Public & Private Subnet Design (In Simple Terms)
- Put resources that need direct internet access (like web servers) in a public subnet, and keep internal resources (like databases or backend servers) in a private subnet. Use a NAT Gateway to let private subnet resources access the internet outbound only for updates, while keeping them hidden from incoming internet traffic. This setup improves security and reduces exposure.
### 34. EBS for Persistent Storage (In Simple Terms)
- Use EBS volumes to store important data because they stay intact even if the EC2 instance stops or restarts, unlike instance store, which is temporary and gets erased. Before taking snapshots, always flush application caches to make sure your backups are complete and consistent.
- EBS snapshots only save data written to the volume, so any data still in the OS or app cache might not be captured unless flushed first.
- It’s best to separate the OS and data onto different EBS volumes for easier management and backups, even though root volume persistence is supported.
- By default, data on non-root EBS volumes is kept safe even if you stop or terminate the EC2 instance (unless you manually set “Delete on Termination” to true).
### 35. IAM role error in VPC Flow Logs 
- An IAM role error in VPC Flow Logs happens when the role linked to the flow log doesn’t have the right permissions or trust relationship for AWS to deliver logs to CloudWatch or S3. Once a flow log is created, you cannot change its IAM role, so fixing the error requires deleting and recreating the flow log with a properly configured role. This ensures the flow log has the access it needs to write data securely.
### 36. Safely Testing RDS Upgrades
- Before upgrading a production RDS instance, create a DB snapshot and restore it into a new instance. Upgrade the new instance and test thoroughly. This avoids risking production downtime and ensures compatibility with your workload.
### 37. HDD-backed EBS Vs SSD-backed EBS
- HDD-backed EBS volumes (st1 and sc1) cost less because they are designed for large, sequential data access like backups or logs, where speed isn’t critical.
- SSD-backed EBS volumes (gp2, gp3, io1) are more expensive because they provide fast random access and low latency, which is needed for things like boot volumes and databases.
- 👉 Simple rule: HDD = cheaper but slower, SSD = faster but costs more.
### 38. SSD-Backed Volumes for EC2 Boot Disks
- Boot volumes in EC2 require SSD-backed EBS volumes like gp2, gp3, or io1 for fast random access. HDD-backed volumes like st1 and sc1 are for cost-effective large sequential workloads (e.g., log processing) and are not supported for booting instances.
### 39. S3 Delete Markers in Versioning
- When S3 versioning is turned on, deleting a file doesn’t remove it — instead, S3 adds a delete marker to hide the file. You can recover the deleted file anytime by removing the delete marker, which makes the older version visible again. This helps protect against accidental deletions.
-  GET requests do not retrieve delete marker objects
### 40. Replication Status in S3
- Replication status shows if an object in your S3 bucket has been successfully copied to the destination bucket in a replication setup. It tells you if replication is “COMPLETED”, “PENDING”, “FAILED”, or “REPLICA” (for already replicated objects). This helps you track and troubleshoot replication progress easily.
### 41. S3 Inventory for Object Replication Status
- S3 Inventory creates automated reports that show the replication status of objects in your buckets. It’s a simple way to track and identify failed replications across buckets, helping you monitor and fix issues at scale.
### 42. SSE-KMS for Encryption with Auditability
- Use SSE-KMS when you want AWS to handle encryption key management while providing full audit logs of key usage for compliance and security monitoring.
- For SSE-S3, AWS manages the keys, but it lacks detailed audit logs for key usage.
### 43. Direct Connect 
- AWS Direct Connect is a dedicated, private network connection between your on-premises data center and AWS. It’s faster and more secure than using the public internet because it gives you a direct line into AWS.
### 44. Public Virtual Interface
- A Public VIF is a setup on Direct Connect that lets you access AWS public services (like S3, DynamoDB, etc.) over the private connection. Even though S3 is a public service, the Public VIF lets you reach it securely without going over the internet.
### 45. Public VIF for S3 over Direct Connect
- When you want to access S3 buckets from your on-premises network through AWS Direct Connect, you need to set up a Public Virtual Interface (Public VIF) because S3 is a public AWS service. This allows your on-premises systems to securely reach S3 over the private Direct Connect link.
### 46. File Gateway for NFS/SMB Integration
- AWS File Gateway lets your on-premises apps access Amazon S3 as if it’s a local file share using NFS or SMB protocols. It’s perfect for moving file-based workloads to the cloud and creating a hybrid storage setup without changing your existing applications.
### 47. Multi-AZ for High Availability, Read Replicas for Scaling Reads
- Multi-AZ keeps a standby database in another Availability Zone with synchronous replication, so if the main DB fails, it automatically switches over for high availability. Read Replicas use asynchronous replication to handle read-heavy traffic and can even be placed in other regions to improve performance for global users.
- Multi-AZ follows synchronous replication and spans at least two Availability Zones within a single region. Read replicas follow asynchronous replication and can be within an Availability Zone, Cross-AZ, or Cross-Region.
### 48. CloudWatch Metrics for S3 5xx Monitoring
- S3 occasionally returns 5xx server errors (like 500 Internal Server Error) due to transient issues. AWS recommends retrying the request with exponential backoff as most of these errors are temporary. CloudWatch can monitor 5xxError metrics. 
- Turn on CloudWatch metrics to track 5xx errors in S3, which indicate server-side problems. Set up alerts to notify your team quickly, and use retry logic with exponential backoff in your apps to handle these errors gracefully and improve reliability.
### 49. S3 RTC for Replication SLA and Alerts
- S3 Replication Time Control (RTC) ensures your data is replicated to the destination bucket within 15 minutes, meeting a strict SLA. It also lets you set up automatic alerts if replication fails, making it an easy, AWS-managed way to monitor and guarantee replication performance.
### 50. File Gateway for Hybrid File Storage
- To migrate on-premises files to AWS and maintain access from both local systems and the cloud, use File Gateway. It supports NFS/SMB access and stores data as S3 objects with low management overhead.


# Cost and Performance Optimization

### 1. ASG Self-Healing for High Availability

- An Auto Scaling Group (ASG) continuously monitors the health of its EC2 instances using health checks. If an instance is marked as unhealthy—either by EC2 status checks, ELB health checks, or both—the ASG will terminate it and launch a new one automatically to maintain the desired capacity.
- This is one of ASG’s core features—self-healing infrastructure. As soon as the instance is confirmed unhealthy (after the grace period), it is replaced to ensure application availability.

### 2. Volume Gateway for Hybrid iSCSI Block Storage

- AWS EBS and Volume Gateway both provide volumes, and those volumes use block storage under the hood.
- Use AWS Storage Gateway – Volume Gateway when your on-premises systems need to keep using iSCSI **block access** with low latency, while also storing the main data in AWS for cost savings, backups, and disaster recovery.

### 3. Use Cost Allocation Tags with Cost Explorer for Accurate Cost Reporting

- To track the costs of Elastic IPs (EIPs) per department, you should apply Cost Allocation Tags to each EIP. These tags (like Department, Project, etc.) can be activated in the billing dashboard. Once tagged, you can use AWS Cost Explorer to filter and generate reports that break down EIP costs by these tags, giving management clear visibility into usage and spend.
- Regular tags alone don't enable billing reports—you need to activate them as cost allocation tags.

### 4. Spot Instances for Low-Cost Batch Jobs

- For non-critical, fault-tolerant, and resumable jobs like daily reports or batch processing, use EC2 Spot Instances to save significantly on compute costs without impacting reliability.
- Spot instances can be used in fault-tolerant systems — not that spot instances make systems fault-tolerant.
- Spot instances are cheap but unreliable (they can be stopped anytime), so they’re only suitable for systems that are already designed to tolerate failures — meaning the system keeps working even if some parts (like a spot instance) go down.

### 5. S3 + CloudFront for Scalable File Delivery

- For distributing large, static files to many users cost-effectively, store the files in Amazon S3 and distribute them through Amazon CloudFront. This improves performance, handles traffic spikes, and reduces EC2/EFS costs.

### 6. RAID 0 for Performance with gp2 Volumes

- RAID 0 (also called striping) is a way to combine two or more disks into one faster virtual drive by splitting the data across them evenly. This improves speed and IOPS because each disk handles part of the work at the same time.
- gp2 volumes deliver performance that scales with size, up to a maximum of 10,000 IOPS per volume. If your 8 TB gp2 volume is maxing out its IOPS, splitting the data across two 4 TB volumes and combining them using RAID 0 (striping) allows you to double the throughput and IOPS capacity while keeping costs roughly the same (since total storage stays 8 TB).
- This helps improve speed and performance because each drive shares the workload. But if one drive fails, you lose everything, so it’s only good for data you can easily replace.

### 7. Use AWS Backup for Multi-Account Backup Management

- AWS Backup simplifies creating centralized, automated backup plans that support multi-account and cross-region replication, using tags to manage different environments. It eliminates the complexity of custom scripts or manual scheduling.
- AWS Backup is the right service for centralized backup management.
- It allows creating centralized backup plans that span across multiple accounts (via AWS Organizations).
- Tags can help apply different backup policies for different environments (Prod/Dev/Test).

### 8. Optimize Large S3 Uploads

- Use Multipart Uploads to split large files into smaller parts and upload them in parallel for faster, more reliable transfers. For global teams, enable S3 Transfer Acceleration to speed up uploads by routing data through AWS’s high-speed edge network.

### 9. Direct Connect + VPN for Secure Hybrid Connections

- By combining AWS Direct Connect (for fast, dedicated bandwidth and low latency) with a VPN tunnel (for encryption), you get a secure and reliable connection between your on-premises network and AWS in a hybrid cloud setup.
- Adding a VPN tunnel over Direct Connect ensures encryption of data in transit.

### 10. Cost Allocation Tags for S3 Bucket Cost Tracking

- Cost allocation tags let you track and filter costs for individual resources like S3 buckets.
  - Add a tag (e.g., Project: MediaContent) to each bucket.
  - Go to the AWS Billing console and enable the tag in Cost Allocation Tags.
  - Use Cost Explorer to view cost reports filtered by that tag.
- This gives you detailed cost visibility for each S3 bucket, making it easier to manage and optimize spending.

### 11. Dedicated Instances for Single-Tenant Compliance

- Use Dedicated Instances when you need your EC2 workloads to run on hardware that’s not shared with other AWS customers (single-tenant) for compliance, but still want to keep costs lower. Pick Dedicated Hosts only if you need full control of the physical server or have BYOL licensing requirements.

### 12. High-Resolution Metrics for Sub-Minute Monitoring

Use CloudWatch high-resolution metrics to track data at intervals under 1 minute by pushing metrics every few seconds. This is perfect for real-time or latency-sensitive workloads where you need faster and more detailed monitoring.

- EC2 detailed monitoring Provides 1-minute metrics(not under 1 minute).

### 13. Elastic Beanstalk Rolling deployments

- Elastic Beanstalk Rolling deployments update a few EC2 instances at a time with the new app version while the others continue serving traffic using the old version. This means no additional EC2 instances are launched during deployment (no extra cost).

### 14. AWS Shield Advanced for Enterprise DDoS Protection

- AWS Shield Advanced protects important websites from big DDoS attacks. It gives 24/7 expert help, blocks attacks fast, and even pays back extra AWS costs if your servers scale up during an attack. It’s perfect for businesses that need their websites to stay online all the time.

### 15. Demand-Based Scaling for Real-Time Workload Changes

- Demand-based scaling lets an Auto Scaling Group (ASG) automatically add or remove EC2 instances based on real-time metrics like CPU usage. For example, if CPU usage goes above 50%, the ASG adds more servers to handle the load, and when demand drops, it reduces servers to save costs. This keeps your app fast and cost-efficient during workload changes.

### 16. Cloudfront Cookie Forwarding

- Cookie forwarding in CloudFront means CloudFront passes the cookies from the user’s browser to your origin server (like an ALB or EC2).
- This is important because cookies often carry session information (like login or shopping cart data). If CloudFront doesn’t forward them, the origin server won’t know which user is making the request, and the user might be treated like a new session every time.
- Key Point: Enabling cookie forwarding makes sure user sessions stay consistent when CloudFront is in front of your app.

### 17. Forward Cookies in CloudFront for Session Persistence

- When CloudFront sits in front of an ALB using sticky sessions, it must forward all cookies to pass session info properly. If cookies aren’t forwarded, CloudFront treats every request as a new session, causing users to re-authenticate repeatedly. Enabling cookie forwarding in CloudFront ensures session persistence works correctly with the ALB.

### 18. EFS Access Points for Per-Directory Access Control

- Amazon EFS Access Points let you set up custom entry points into an EFS file system, each with its own user and group permissions. This makes it easy to give different apps or IAM roles access to specific directories, which is perfect for multi-tenant environments like containers needing isolated storage.
- EFS Access Points let you give different users or apps their own folder in an EFS file system with separate permissions. This makes it easy to control who can access which directory, perfect for setups where many users share the same storage.

### 19. ClientConnections Metric for EFS Usage Tracking

- The ClientConnections metric in Amazon EFS shows how many EC2 instances or servers are actively connected to your file system right now. It helps you track usage and see how many clients are using EFS at any given time. Summing it over time gives the total number of connections during that period.

### 20. DS Proxy for Efficient Connection Management

- Amazon RDS Proxy acts as a middle layer between your app and the database to pool and reuse connections, instead of opening a new one for every query. This is especially helpful for serverless apps like Lambda, which can create too many connections during traffic spikes. It prevents database overload and keeps performance stable.

### 21. S3 Glacier Free Retrieval Allowance

- AWS gives you 10 GB of free S3 Glacier data retrieval each month. If you download more than 10 GB, you’ll be charged for the extra data. If you didn’t see charges before, it’s likely because your retrievals stayed within this free limit.

### 22. VPC Endpoints for Private and Cost-Effective Access

- If you want to set up a private network connection between a File Gateway and Amazon S3 for secure access, Setup the private connection within an Amazon Virtual Private Cloud (Amazon VPC) by using VPC endpoints
- A VPC endpoint lets your VPC connect to AWS services like S3 privately, without using the internet, NAT, or VPN. This keeps traffic inside AWS’s network, making it more secure and often cheaper than sending data through the public internet.

### 23. st1 for High-Throughput at Low Cost

- EBS st1 is a cheap storage type made for jobs that read and write big files in order (like logs, big data, or backups). It’s fast for sequential work but not good for random reads and writes.
- st1 (Throughput Optimized HDD): Faster and designed for big, frequent workloads like log processing, data warehouses, or big data jobs.
- sc1 (Cold HDD): Slower and cheaper, made for rarely accessed data like backups or archives where performance doesn’t matter much.
- HDD = slower and cheaper, SSD = faster and costlier.
